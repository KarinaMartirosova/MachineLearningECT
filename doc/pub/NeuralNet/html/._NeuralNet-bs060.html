<!--
Automatically generated HTML file from DocOnce source
(https://github.com/hplgit/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/hplgit/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Data Analysis and Machine Learning: Neural networks, from the simple perceptron to deep learning">

<title>Data Analysis and Machine Learning: Neural networks, from the simple perceptron to deep learning</title>

<!-- Bootstrap style: bootstrap -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->

<style type="text/css">

/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}

/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>


</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Neural networks', 2, None, '___sec0'),
              ('Artificial neurons', 2, None, '___sec1'),
              ('Neural network types', 2, None, '___sec2'),
              ('Feed-forward neural networks', 2, None, '___sec3'),
              ('Convolutional Neural Network', 2, None, '___sec4'),
              ('Recurrent neural networks', 2, None, '___sec5'),
              ('Other types of networks', 2, None, '___sec6'),
              ('Multilayer perceptrons', 2, None, '___sec7'),
              ('Why multilayer perceptrons?', 2, None, '___sec8'),
              ('Mathematical model', 2, None, '___sec9'),
              ('Mathematical model', 2, None, '___sec10'),
              ('Mathematical model', 2, None, '___sec11'),
              ('Mathematical model', 2, None, '___sec12'),
              ('Mathematical model', 2, None, '___sec13'),
              ('Matrix-vector notation', 3, None, '___sec14'),
              ('Matrix-vector notation  and activation', 3, None, '___sec15'),
              ('Activation functions', 3, None, '___sec16'),
              ('Activation functions, Logistic and Hyperbolic ones',
               3,
               None,
               '___sec17'),
              ('Relevance', 3, None, '___sec18'),
              ('The multilayer  perceptron (MLP)', 2, None, '___sec19'),
              ('From one to many layers, the universal approximation theorem',
               2,
               None,
               '___sec20'),
              ('Deriving the back propagation code for a multilayer perceptron '
               'model',
               2,
               None,
               '___sec21'),
              ('Definitions', 2, None, '___sec22'),
              ('Derivatives and the chain rule', 2, None, '___sec23'),
              ('Derivative of the cost function', 2, None, '___sec24'),
              ('Bringing it together, first back propagation equation',
               2,
               None,
               '___sec25'),
              ('Derivatives in terms of $z_j^L$', 2, None, '___sec26'),
              ('Bringing it together', 2, None, '___sec27'),
              ('Final back propagating equation', 2, None, '___sec28'),
              ('Setting up the Back propagation algorithm',
               2,
               None,
               '___sec29'),
              ('Setting up a Multi-layer perceptron model for classification',
               2,
               None,
               '___sec30'),
              ('Defining the cost function', 2, None, '___sec31'),
              ('Example: binary classification problem', 2, None, '___sec32'),
              ('The Softmax function', 2, None, '___sec33'),
              ('Developing a code for doing neural networks with back '
               'propagation',
               2,
               None,
               '___sec34'),
              ('Collect and pre-process data', 2, None, '___sec35'),
              ('Train and test datasets', 2, None, '___sec36'),
              ('Define model and architecture', 2, None, '___sec37'),
              ('Layers', 2, None, '___sec38'),
              ('Weights and biases', 2, None, '___sec39'),
              ('Feed-forward pass', 2, None, '___sec40'),
              ('Matrix multiplications', 2, None, '___sec41'),
              ('Choose cost function and optimizer', 2, None, '___sec42'),
              ('Optimizing the cost function', 2, None, '___sec43'),
              ('Regularization', 2, None, '___sec44'),
              ('Matrix  multiplication', 2, None, '___sec45'),
              ('Improving performance', 2, None, '___sec46'),
              ('Full object-oriented implementation', 2, None, '___sec47'),
              ('Evaluate model performance on test data', 2, None, '___sec48'),
              ('Adjust hyperparameters', 2, None, '___sec49'),
              ('Visualization', 2, None, '___sec50'),
              ('scikit-learn implementation', 2, None, '___sec51'),
              ('Visualization', 2, None, '___sec52'),
              ('Building neural networks in Tensorflow and Keras',
               2,
               None,
               '___sec53'),
              ('Tensorflow', 2, None, '___sec54'),
              ('Collect and pre-process data', 2, None, '___sec55'),
              ('Using TensorFlow backend', 2, None, '___sec56'),
              ('Optimizing and using gradient descent', 2, None, '___sec57'),
              ('Using Keras', 2, None, '___sec58'),
              ('The Breast Cancer Data, now with Keras', 2, None, '___sec59'),
              ('Which activation function should I use?', 2, None, '___sec60'),
              ('Is the Logistic activation function (Sigmoid)  our choice?',
               2,
               None,
               '___sec61'),
              ('The derivative of the Logistic funtion', 2, None, '___sec62'),
              ('The RELU function family', 2, None, '___sec63'),
              ('Which activation function should we use?', 2, None, '___sec64'),
              ('A top-down perspective on Neural networks',
               2,
               None,
               '___sec65'),
              ('Limitations of supervised learning with deep networks',
               2,
               None,
               '___sec66'),
              ('Examples: Pulsar identification', 2, None, '___sec67'),
              ('Preprocessing and Statistical Analysis of the Data',
               3,
               None,
               '___sec68')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



    
<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="NeuralNet-bs.html">Data Analysis and Machine Learning: Neural networks, from the simple perceptron to deep learning</a>
  </div>

  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs001.html#___sec0" style="font-size: 80%;"><b>Neural networks</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs002.html#___sec1" style="font-size: 80%;"><b>Artificial neurons</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs003.html#___sec2" style="font-size: 80%;"><b>Neural network types</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs004.html#___sec3" style="font-size: 80%;"><b>Feed-forward neural networks</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs005.html#___sec4" style="font-size: 80%;"><b>Convolutional Neural Network</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs006.html#___sec5" style="font-size: 80%;"><b>Recurrent neural networks</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs007.html#___sec6" style="font-size: 80%;"><b>Other types of networks</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs008.html#___sec7" style="font-size: 80%;"><b>Multilayer perceptrons</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs009.html#___sec8" style="font-size: 80%;"><b>Why multilayer perceptrons?</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs010.html#___sec9" style="font-size: 80%;"><b>Mathematical model</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs011.html#___sec10" style="font-size: 80%;"><b>Mathematical model</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs012.html#___sec11" style="font-size: 80%;"><b>Mathematical model</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs013.html#___sec12" style="font-size: 80%;"><b>Mathematical model</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs014.html#___sec13" style="font-size: 80%;"><b>Mathematical model</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs015.html#___sec14" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Matrix-vector notation</a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs016.html#___sec15" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Matrix-vector notation  and activation</a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs017.html#___sec16" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Activation functions</a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs018.html#___sec17" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Activation functions, Logistic and Hyperbolic ones</a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs019.html#___sec18" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Relevance</a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs020.html#___sec19" style="font-size: 80%;"><b>The multilayer  perceptron (MLP)</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs021.html#___sec20" style="font-size: 80%;"><b>From one to many layers, the universal approximation theorem</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs022.html#___sec21" style="font-size: 80%;"><b>Deriving the back propagation code for a multilayer perceptron model</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs023.html#___sec22" style="font-size: 80%;"><b>Definitions</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs024.html#___sec23" style="font-size: 80%;"><b>Derivatives and the chain rule</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs025.html#___sec24" style="font-size: 80%;"><b>Derivative of the cost function</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs026.html#___sec25" style="font-size: 80%;"><b>Bringing it together, first back propagation equation</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs027.html#___sec26" style="font-size: 80%;"><b>Derivatives in terms of \( z_j^L \)</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs028.html#___sec27" style="font-size: 80%;"><b>Bringing it together</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs029.html#___sec28" style="font-size: 80%;"><b>Final back propagating equation</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs030.html#___sec29" style="font-size: 80%;"><b>Setting up the Back propagation algorithm</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs031.html#___sec30" style="font-size: 80%;"><b>Setting up a Multi-layer perceptron model for classification</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs032.html#___sec31" style="font-size: 80%;"><b>Defining the cost function</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs033.html#___sec32" style="font-size: 80%;"><b>Example: binary classification problem</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs034.html#___sec33" style="font-size: 80%;"><b>The Softmax function</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs035.html#___sec34" style="font-size: 80%;"><b>Developing a code for doing neural networks with back propagation</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs036.html#___sec35" style="font-size: 80%;"><b>Collect and pre-process data</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs037.html#___sec36" style="font-size: 80%;"><b>Train and test datasets</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs038.html#___sec37" style="font-size: 80%;"><b>Define model and architecture</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs039.html#___sec38" style="font-size: 80%;"><b>Layers</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs040.html#___sec39" style="font-size: 80%;"><b>Weights and biases</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs041.html#___sec40" style="font-size: 80%;"><b>Feed-forward pass</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs042.html#___sec41" style="font-size: 80%;"><b>Matrix multiplications</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs043.html#___sec42" style="font-size: 80%;"><b>Choose cost function and optimizer</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs044.html#___sec43" style="font-size: 80%;"><b>Optimizing the cost function</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs045.html#___sec44" style="font-size: 80%;"><b>Regularization</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs046.html#___sec45" style="font-size: 80%;"><b>Matrix  multiplication</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs047.html#___sec46" style="font-size: 80%;"><b>Improving performance</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs048.html#___sec47" style="font-size: 80%;"><b>Full object-oriented implementation</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs049.html#___sec48" style="font-size: 80%;"><b>Evaluate model performance on test data</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs050.html#___sec49" style="font-size: 80%;"><b>Adjust hyperparameters</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs051.html#___sec50" style="font-size: 80%;"><b>Visualization</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs052.html#___sec51" style="font-size: 80%;"><b>scikit-learn implementation</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs053.html#___sec52" style="font-size: 80%;"><b>Visualization</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs054.html#___sec53" style="font-size: 80%;"><b>Building neural networks in Tensorflow and Keras</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs055.html#___sec54" style="font-size: 80%;"><b>Tensorflow</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs056.html#___sec55" style="font-size: 80%;"><b>Collect and pre-process data</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs057.html#___sec56" style="font-size: 80%;"><b>Using TensorFlow backend</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs058.html#___sec57" style="font-size: 80%;"><b>Optimizing and using gradient descent</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs059.html#___sec58" style="font-size: 80%;"><b>Using Keras</b></a></li>
     <!-- navigation toc: --> <li><a href="#___sec59" style="font-size: 80%;"><b>The Breast Cancer Data, now with Keras</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs061.html#___sec60" style="font-size: 80%;"><b>Which activation function should I use?</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs062.html#___sec61" style="font-size: 80%;"><b>Is the Logistic activation function (Sigmoid)  our choice?</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs063.html#___sec62" style="font-size: 80%;"><b>The derivative of the Logistic funtion</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs064.html#___sec63" style="font-size: 80%;"><b>The RELU function family</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs065.html#___sec64" style="font-size: 80%;"><b>Which activation function should we use?</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs066.html#___sec65" style="font-size: 80%;"><b>A top-down perspective on Neural networks</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs067.html#___sec66" style="font-size: 80%;"><b>Limitations of supervised learning with deep networks</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs068.html#___sec67" style="font-size: 80%;"><b>Examples: Pulsar identification</b></a></li>
     <!-- navigation toc: --> <li><a href="._NeuralNet-bs068.html#___sec68" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Preprocessing and Statistical Analysis of the Data</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->

<div class="container">

<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->

<a name="part0060"></a>
<!-- !split -->

<h2 id="___sec59" class="anchor">The Breast Cancer Data, now with Keras </h2>

<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">tensorflow</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">tf</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">tensorflow.keras.layers</span> <span style="color: #008000; font-weight: bold">import</span> Input
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">tensorflow.keras.models</span> <span style="color: #008000; font-weight: bold">import</span> Sequential      <span style="color: #408080; font-style: italic">#This allows appending layers to existing models</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">tensorflow.keras.layers</span> <span style="color: #008000; font-weight: bold">import</span> Dense           <span style="color: #408080; font-style: italic">#This allows defining the characteristics of a particular layer</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">tensorflow.keras</span> <span style="color: #008000; font-weight: bold">import</span> optimizers             <span style="color: #408080; font-style: italic">#This allows using whichever optimiser we want (sgd,adam,RMSprop)</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">tensorflow.keras</span> <span style="color: #008000; font-weight: bold">import</span> regularizers           <span style="color: #408080; font-style: italic">#This allows using whichever regularizer we want (l1,l2,l1_l2)</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">tensorflow.keras.utils</span> <span style="color: #008000; font-weight: bold">import</span> to_categorical   <span style="color: #408080; font-style: italic">#This allows using categorical cross entropy as the cost function</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">matplotlib.pyplot</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">plt</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">seaborn</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">sns</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.model_selection</span> <span style="color: #008000; font-weight: bold">import</span> train_test_split <span style="color: #008000; font-weight: bold">as</span> splitter
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.datasets</span> <span style="color: #008000; font-weight: bold">import</span> load_breast_cancer
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">pickle</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">os</span> 


<span style="color: #BA2121; font-style: italic">&quot;&quot;&quot;Load breast cancer dataset&quot;&quot;&quot;</span>

np<span style="color: #666666">.</span>random<span style="color: #666666">.</span>seed(<span style="color: #666666">0</span>)        <span style="color: #408080; font-style: italic">#create same seed for random number every time</span>

cancer<span style="color: #666666">=</span>load_breast_cancer()      <span style="color: #408080; font-style: italic">#Download breast cancer dataset</span>

inputs<span style="color: #666666">=</span>cancer<span style="color: #666666">.</span>data                     <span style="color: #408080; font-style: italic">#Feature matrix of 569 rows (samples) and 30 columns (parameters)</span>
outputs<span style="color: #666666">=</span>cancer<span style="color: #666666">.</span>target                  <span style="color: #408080; font-style: italic">#Label array of 569 rows (0 for benign and 1 for malignant)</span>
labels<span style="color: #666666">=</span>cancer<span style="color: #666666">.</span>feature_names[<span style="color: #666666">0</span>:<span style="color: #666666">30</span>]

<span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&#39;The content of the breast cancer dataset is:&#39;</span>)      <span style="color: #408080; font-style: italic">#Print information about the datasets</span>
<span style="color: #008000; font-weight: bold">print</span>(labels)
<span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&#39;-------------------------&#39;</span>)
<span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&quot;inputs =  &quot;</span> <span style="color: #666666">+</span> <span style="color: #008000">str</span>(inputs<span style="color: #666666">.</span>shape))
<span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&quot;outputs =  &quot;</span> <span style="color: #666666">+</span> <span style="color: #008000">str</span>(outputs<span style="color: #666666">.</span>shape))
<span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&quot;labels =  &quot;</span><span style="color: #666666">+</span> <span style="color: #008000">str</span>(labels<span style="color: #666666">.</span>shape))

x<span style="color: #666666">=</span>inputs      <span style="color: #408080; font-style: italic">#Reassign the Feature and Label matrices to other variables</span>
y<span style="color: #666666">=</span>outputs

<span style="color: #408080; font-style: italic">#%% </span>

<span style="color: #408080; font-style: italic"># Visualisation of dataset (for correlation analysis)</span>

plt<span style="color: #666666">.</span>figure()
plt<span style="color: #666666">.</span>scatter(x[:,<span style="color: #666666">0</span>],x[:,<span style="color: #666666">2</span>],s<span style="color: #666666">=40</span>,c<span style="color: #666666">=</span>y,cmap<span style="color: #666666">=</span>plt<span style="color: #666666">.</span>cm<span style="color: #666666">.</span>Spectral)
plt<span style="color: #666666">.</span>xlabel(<span style="color: #BA2121">&#39;Mean radius&#39;</span>,fontweight<span style="color: #666666">=</span><span style="color: #BA2121">&#39;bold&#39;</span>)
plt<span style="color: #666666">.</span>ylabel(<span style="color: #BA2121">&#39;Mean perimeter&#39;</span>,fontweight<span style="color: #666666">=</span><span style="color: #BA2121">&#39;bold&#39;</span>)
plt<span style="color: #666666">.</span>show()

plt<span style="color: #666666">.</span>figure()
plt<span style="color: #666666">.</span>scatter(x[:,<span style="color: #666666">5</span>],x[:,<span style="color: #666666">6</span>],s<span style="color: #666666">=40</span>,c<span style="color: #666666">=</span>y, cmap<span style="color: #666666">=</span>plt<span style="color: #666666">.</span>cm<span style="color: #666666">.</span>Spectral)
plt<span style="color: #666666">.</span>xlabel(<span style="color: #BA2121">&#39;Mean compactness&#39;</span>,fontweight<span style="color: #666666">=</span><span style="color: #BA2121">&#39;bold&#39;</span>)
plt<span style="color: #666666">.</span>ylabel(<span style="color: #BA2121">&#39;Mean concavity&#39;</span>,fontweight<span style="color: #666666">=</span><span style="color: #BA2121">&#39;bold&#39;</span>)
plt<span style="color: #666666">.</span>show()


plt<span style="color: #666666">.</span>figure()
plt<span style="color: #666666">.</span>scatter(x[:,<span style="color: #666666">0</span>],x[:,<span style="color: #666666">1</span>],s<span style="color: #666666">=40</span>,c<span style="color: #666666">=</span>y,cmap<span style="color: #666666">=</span>plt<span style="color: #666666">.</span>cm<span style="color: #666666">.</span>Spectral)
plt<span style="color: #666666">.</span>xlabel(<span style="color: #BA2121">&#39;Mean radius&#39;</span>,fontweight<span style="color: #666666">=</span><span style="color: #BA2121">&#39;bold&#39;</span>)
plt<span style="color: #666666">.</span>ylabel(<span style="color: #BA2121">&#39;Mean texture&#39;</span>,fontweight<span style="color: #666666">=</span><span style="color: #BA2121">&#39;bold&#39;</span>)
plt<span style="color: #666666">.</span>show()

plt<span style="color: #666666">.</span>figure()
plt<span style="color: #666666">.</span>scatter(x[:,<span style="color: #666666">2</span>],x[:,<span style="color: #666666">1</span>],s<span style="color: #666666">=40</span>,c<span style="color: #666666">=</span>y,cmap<span style="color: #666666">=</span>plt<span style="color: #666666">.</span>cm<span style="color: #666666">.</span>Spectral)
plt<span style="color: #666666">.</span>xlabel(<span style="color: #BA2121">&#39;Mean perimeter&#39;</span>,fontweight<span style="color: #666666">=</span><span style="color: #BA2121">&#39;bold&#39;</span>)
plt<span style="color: #666666">.</span>ylabel(<span style="color: #BA2121">&#39;Mean compactness&#39;</span>,fontweight<span style="color: #666666">=</span><span style="color: #BA2121">&#39;bold&#39;</span>)
plt<span style="color: #666666">.</span>show()


<span style="color: #408080; font-style: italic"># Generate training and testing datasets</span>

<span style="color: #408080; font-style: italic">#Select features relevant to classification (texture,perimeter,compactness and symmetery) </span>
<span style="color: #408080; font-style: italic">#and add to input matrix</span>

temp1<span style="color: #666666">=</span>np<span style="color: #666666">.</span>reshape(x[:,<span style="color: #666666">1</span>],(<span style="color: #008000">len</span>(x[:,<span style="color: #666666">1</span>]),<span style="color: #666666">1</span>))
temp2<span style="color: #666666">=</span>np<span style="color: #666666">.</span>reshape(x[:,<span style="color: #666666">2</span>],(<span style="color: #008000">len</span>(x[:,<span style="color: #666666">2</span>]),<span style="color: #666666">1</span>))
X<span style="color: #666666">=</span>np<span style="color: #666666">.</span>hstack((temp1,temp2))      
temp<span style="color: #666666">=</span>np<span style="color: #666666">.</span>reshape(x[:,<span style="color: #666666">5</span>],(<span style="color: #008000">len</span>(x[:,<span style="color: #666666">5</span>]),<span style="color: #666666">1</span>))
X<span style="color: #666666">=</span>np<span style="color: #666666">.</span>hstack((X,temp))       
temp<span style="color: #666666">=</span>np<span style="color: #666666">.</span>reshape(x[:,<span style="color: #666666">8</span>],(<span style="color: #008000">len</span>(x[:,<span style="color: #666666">8</span>]),<span style="color: #666666">1</span>))
X<span style="color: #666666">=</span>np<span style="color: #666666">.</span>hstack((X,temp))       

X_train,X_test,y_train,y_test<span style="color: #666666">=</span>splitter(X,y,test_size<span style="color: #666666">=0.1</span>)   <span style="color: #408080; font-style: italic">#Split datasets into training and testing</span>

y_train<span style="color: #666666">=</span>to_categorical(y_train)     <span style="color: #408080; font-style: italic">#Convert labels to categorical when using categorical cross entropy</span>
y_test<span style="color: #666666">=</span>to_categorical(y_test)

<span style="color: #008000; font-weight: bold">del</span> temp1,temp2,temp

<span style="color: #408080; font-style: italic"># %%</span>

<span style="color: #408080; font-style: italic"># Define tunable parameters&quot;</span>

eta<span style="color: #666666">=</span>np<span style="color: #666666">.</span>logspace(<span style="color: #666666">-3</span>,<span style="color: #666666">-1</span>,<span style="color: #666666">3</span>)                    <span style="color: #408080; font-style: italic">#Define vector of learning rates (parameter to SGD optimiser)</span>
lamda<span style="color: #666666">=0.01</span>                                  <span style="color: #408080; font-style: italic">#Define hyperparameter</span>
n_layers<span style="color: #666666">=2</span>                                  <span style="color: #408080; font-style: italic">#Define number of hidden layers in the model</span>
n_neuron<span style="color: #666666">=</span>np<span style="color: #666666">.</span>logspace(<span style="color: #666666">0</span>,<span style="color: #666666">3</span>,<span style="color: #666666">4</span>,dtype<span style="color: #666666">=</span><span style="color: #008000">int</span>)       <span style="color: #408080; font-style: italic">#Define number of neurons per layer</span>
epochs<span style="color: #666666">=100</span>                                   <span style="color: #408080; font-style: italic">#Number of reiterations over the input data</span>
batch_size<span style="color: #666666">=100</span>                              <span style="color: #408080; font-style: italic">#Number of samples per gradient update</span>

<span style="color: #408080; font-style: italic"># %%</span>

<span style="color: #BA2121; font-style: italic">&quot;&quot;&quot;Define function to return Deep Neural Network model&quot;&quot;&quot;</span>

<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">NN_model</span>(inputsize,n_layers,n_neuron,eta,lamda):
    model<span style="color: #666666">=</span>Sequential()      
    <span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(n_layers):       <span style="color: #408080; font-style: italic">#Run loop to add hidden layers to the model</span>
        <span style="color: #008000; font-weight: bold">if</span> (i<span style="color: #666666">==0</span>):                  <span style="color: #408080; font-style: italic">#First layer requires input dimensions</span>
            model<span style="color: #666666">.</span>add(Dense(n_neuron,activation<span style="color: #666666">=</span><span style="color: #BA2121">&#39;relu&#39;</span>,kernel_regularizer<span style="color: #666666">=</span>regularizers<span style="color: #666666">.</span>l2(lamda),input_dim<span style="color: #666666">=</span>inputsize))
        <span style="color: #008000; font-weight: bold">else</span>:                       <span style="color: #408080; font-style: italic">#Subsequent layers are capable of automatic shape inferencing</span>
            model<span style="color: #666666">.</span>add(Dense(n_neuron,activation<span style="color: #666666">=</span><span style="color: #BA2121">&#39;relu&#39;</span>,kernel_regularizer<span style="color: #666666">=</span>regularizers<span style="color: #666666">.</span>l2(lamda)))
    model<span style="color: #666666">.</span>add(Dense(<span style="color: #666666">2</span>,activation<span style="color: #666666">=</span><span style="color: #BA2121">&#39;softmax&#39;</span>))  <span style="color: #408080; font-style: italic">#2 outputs - ordered and disordered (softmax for prob)</span>
    sgd<span style="color: #666666">=</span>optimizers<span style="color: #666666">.</span>SGD(lr<span style="color: #666666">=</span>eta)
    model<span style="color: #666666">.</span>compile(loss<span style="color: #666666">=</span><span style="color: #BA2121">&#39;categorical_crossentropy&#39;</span>,optimizer<span style="color: #666666">=</span>sgd,metrics<span style="color: #666666">=</span>[<span style="color: #BA2121">&#39;accuracy&#39;</span>])
    <span style="color: #008000; font-weight: bold">return</span> model

    
Train_accuracy<span style="color: #666666">=</span>np<span style="color: #666666">.</span>zeros((<span style="color: #008000">len</span>(n_neuron),<span style="color: #008000">len</span>(eta)))      <span style="color: #408080; font-style: italic">#Define matrices to store accuracy scores as a function</span>
Test_accuracy<span style="color: #666666">=</span>np<span style="color: #666666">.</span>zeros((<span style="color: #008000">len</span>(n_neuron),<span style="color: #008000">len</span>(eta)))       <span style="color: #408080; font-style: italic">#of learning rate and number of hidden neurons for </span>

<span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(<span style="color: #008000">len</span>(n_neuron)):     <span style="color: #408080; font-style: italic">#run loops over hidden neurons and learning rates to calculate </span>
    <span style="color: #008000; font-weight: bold">for</span> j <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(<span style="color: #008000">len</span>(eta)):      <span style="color: #408080; font-style: italic">#accuracy scores </span>
        DNN_model<span style="color: #666666">=</span>NN_model(X_train<span style="color: #666666">.</span>shape[<span style="color: #666666">1</span>],n_layers,n_neuron[i],eta[j],lamda)
        DNN_model<span style="color: #666666">.</span>fit(X_train,y_train,epochs<span style="color: #666666">=</span>epochs,batch_size<span style="color: #666666">=</span>batch_size,verbose<span style="color: #666666">=1</span>)
        Train_accuracy[i,j]<span style="color: #666666">=</span>DNN_model<span style="color: #666666">.</span>evaluate(X_train,y_train)[<span style="color: #666666">1</span>]
        Test_accuracy[i,j]<span style="color: #666666">=</span>DNN_model<span style="color: #666666">.</span>evaluate(X_test,y_test)[<span style="color: #666666">1</span>]
               

<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">plot_data</span>(x,y,data,title<span style="color: #666666">=</span><span style="color: #008000">None</span>):

    <span style="color: #408080; font-style: italic"># plot results</span>
    fontsize<span style="color: #666666">=16</span>


    fig <span style="color: #666666">=</span> plt<span style="color: #666666">.</span>figure()
    ax <span style="color: #666666">=</span> fig<span style="color: #666666">.</span>add_subplot(<span style="color: #666666">111</span>)
    cax <span style="color: #666666">=</span> ax<span style="color: #666666">.</span>matshow(data, interpolation<span style="color: #666666">=</span><span style="color: #BA2121">&#39;nearest&#39;</span>, vmin<span style="color: #666666">=0</span>, vmax<span style="color: #666666">=1</span>)
    
    cbar<span style="color: #666666">=</span>fig<span style="color: #666666">.</span>colorbar(cax)
    cbar<span style="color: #666666">.</span>ax<span style="color: #666666">.</span>set_ylabel(<span style="color: #BA2121">&#39;accuracy (%)&#39;</span>,rotation<span style="color: #666666">=90</span>,fontsize<span style="color: #666666">=</span>fontsize)
    cbar<span style="color: #666666">.</span>set_ticks([<span style="color: #666666">0</span>,<span style="color: #666666">.2</span>,<span style="color: #666666">.4</span>,<span style="color: #666666">0.6</span>,<span style="color: #666666">0.8</span>,<span style="color: #666666">1.0</span>])
    cbar<span style="color: #666666">.</span>set_ticklabels([<span style="color: #BA2121">&#39;0%&#39;</span>,<span style="color: #BA2121">&#39;20%&#39;</span>,<span style="color: #BA2121">&#39;40%&#39;</span>,<span style="color: #BA2121">&#39;60%&#39;</span>,<span style="color: #BA2121">&#39;80%&#39;</span>,<span style="color: #BA2121">&#39;100%&#39;</span>])

    <span style="color: #408080; font-style: italic"># put text on matrix elements</span>
    <span style="color: #008000; font-weight: bold">for</span> i, x_val <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">enumerate</span>(np<span style="color: #666666">.</span>arange(<span style="color: #008000">len</span>(x))):
        <span style="color: #008000; font-weight: bold">for</span> j, y_val <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">enumerate</span>(np<span style="color: #666666">.</span>arange(<span style="color: #008000">len</span>(y))):
            c <span style="color: #666666">=</span> <span style="color: #BA2121">&quot;${0:.1f}</span><span style="color: #BB6622; font-weight: bold">\\</span><span style="color: #BA2121">%$&quot;</span><span style="color: #666666">.</span>format( <span style="color: #666666">100*</span>data[j,i])  
            ax<span style="color: #666666">.</span>text(x_val, y_val, c, va<span style="color: #666666">=</span><span style="color: #BA2121">&#39;center&#39;</span>, ha<span style="color: #666666">=</span><span style="color: #BA2121">&#39;center&#39;</span>)

    <span style="color: #408080; font-style: italic"># convert axis vaues to to string labels</span>
    x<span style="color: #666666">=</span>[<span style="color: #008000">str</span>(i) <span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> x]
    y<span style="color: #666666">=</span>[<span style="color: #008000">str</span>(i) <span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> y]


    ax<span style="color: #666666">.</span>set_xticklabels([<span style="color: #BA2121">&#39;&#39;</span>]<span style="color: #666666">+</span>x)
    ax<span style="color: #666666">.</span>set_yticklabels([<span style="color: #BA2121">&#39;&#39;</span>]<span style="color: #666666">+</span>y)

    ax<span style="color: #666666">.</span>set_xlabel(<span style="color: #BA2121">&#39;$</span><span style="color: #BB6622; font-weight: bold">\\</span><span style="color: #BA2121">mathrm{learning</span><span style="color: #BB6622; font-weight: bold">\\</span><span style="color: #BA2121"> rate}$&#39;</span>,fontsize<span style="color: #666666">=</span>fontsize)
    ax<span style="color: #666666">.</span>set_ylabel(<span style="color: #BA2121">&#39;$</span><span style="color: #BB6622; font-weight: bold">\\</span><span style="color: #BA2121">mathrm{hidden</span><span style="color: #BB6622; font-weight: bold">\\</span><span style="color: #BA2121"> neurons}$&#39;</span>,fontsize<span style="color: #666666">=</span>fontsize)
    <span style="color: #008000; font-weight: bold">if</span> title <span style="color: #AA22FF; font-weight: bold">is</span> <span style="color: #AA22FF; font-weight: bold">not</span> <span style="color: #008000">None</span>:
        ax<span style="color: #666666">.</span>set_title(title)

    plt<span style="color: #666666">.</span>tight_layout()

    plt<span style="color: #666666">.</span>show()
    
plot_data(eta,n_neuron,Train_accuracy, <span style="color: #BA2121">&#39;training&#39;</span>)
plot_data(eta,n_neuron,Test_accuracy, <span style="color: #BA2121">&#39;testing&#39;</span>)
</pre></div>
<p>
<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._NeuralNet-bs059.html">&laquo;</a></li>
  <li><a href="._NeuralNet-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._NeuralNet-bs052.html">53</a></li>
  <li><a href="._NeuralNet-bs053.html">54</a></li>
  <li><a href="._NeuralNet-bs054.html">55</a></li>
  <li><a href="._NeuralNet-bs055.html">56</a></li>
  <li><a href="._NeuralNet-bs056.html">57</a></li>
  <li><a href="._NeuralNet-bs057.html">58</a></li>
  <li><a href="._NeuralNet-bs058.html">59</a></li>
  <li><a href="._NeuralNet-bs059.html">60</a></li>
  <li class="active"><a href="._NeuralNet-bs060.html">61</a></li>
  <li><a href="._NeuralNet-bs061.html">62</a></li>
  <li><a href="._NeuralNet-bs062.html">63</a></li>
  <li><a href="._NeuralNet-bs063.html">64</a></li>
  <li><a href="._NeuralNet-bs064.html">65</a></li>
  <li><a href="._NeuralNet-bs065.html">66</a></li>
  <li><a href="._NeuralNet-bs066.html">67</a></li>
  <li><a href="._NeuralNet-bs067.html">68</a></li>
  <li><a href="._NeuralNet-bs068.html">69</a></li>
  <li><a href="._NeuralNet-bs061.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->

</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>

<!-- Bootstrap footer
<footer>
<a href="http://..."><img width="250" align=right src="http://..."></a>
</footer>
-->


<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>


</body>
</html>
    

